#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
My AI Agent - ë©€í‹° ì—ì´ì „íŠ¸ AI ì‹œìŠ¤í…œ

ìŒì„± ì¸ì‹, ì´ë©”ì¼ ì²˜ë¦¬, ê¸°íšì„œ ì‘ì„± ë“± ë‹¤ì–‘í•œ AI ê¸°ëŠ¥ì„ ì œê³µí•˜ëŠ” 
í†µí•© ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì˜ ë©”ì¸ Streamlit ì• í”Œë¦¬ì¼€ì´ì…˜ì…ë‹ˆë‹¤.
"""

# CACHE_INVALIDATION_TOKEN: f8a9d2c35e17_20250708_1620
# ìœ„ í† í°ì€ Streamlit ìºì‹œë¥¼ ê°•ì œë¡œ ë¬´íš¨í™”í•˜ê¸° ìœ„í•œ ê²ƒì…ë‹ˆë‹¤.

import sys
import os
import base64
import streamlit as st
import speech_recognition as sr
import threading
import time
import datetime
import shutil
from ui.chat import render_chat_ui
from ui.sidebar import render_sidebar
from ui.analysis import render_analysis_ui
from ui.document import render_document_ui
from ui.email import render_email_ui
from ui.common import init_session_state, play_audio_autoplay_hidden, save_uploaded_file
from ui.voice import start_continuous_voice_recognition, stop_continuous_voice_recognition

# í”„ë¡œì íŠ¸ ëª¨ë“ˆ ì„í¬íŠ¸ë¥¼ ìœ„í•œ ê²½ë¡œ ì„¤ì •
current_script_dir = os.path.dirname(os.path.abspath(__file__))
if current_script_dir not in sys.path:
    sys.path.insert(0, current_script_dir)

# í•˜ìœ„ ëª¨ë“ˆ ê²½ë¡œ ì¶”ê°€
for subdir in ["tools", "ui_components", "agents"]:
    subdir_path = os.path.join(current_script_dir, subdir)
    if subdir_path not in sys.path:
        sys.path.insert(0, subdir_path)

# ì„¤ì • ë° ë¡œê¹… ì´ˆê¸°í™”
from config import config
from logging_config import setup_logging, get_logger
from configs.prompt_loader import get_prompt_text

# --- ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” ---
init_session_state()

# ë¡œê¹… ì„¤ì •
setup_logging(log_level=config.LOG_LEVEL, log_dir=config.LOG_DIR)
logger = get_logger(__name__)

# í•„ìˆ˜ í™˜ê²½ ë³€ìˆ˜ ê²€ì¦
try:
    config.validate_required_keys()
    logger.info("í™˜ê²½ ë³€ìˆ˜ ê²€ì¦ ì™„ë£Œ")
except ValueError as e:
    logger.error(f"í™˜ê²½ ë³€ìˆ˜ ì˜¤ë¥˜: {e}")
    st.error(f"í™˜ê²½ ë³€ìˆ˜ ì„¤ì • ì˜¤ë¥˜: {e}")
    st.stop()

import assistant_core
from ui_components.display_helpers import (
    show_message, show_spinner_ui, show_ai_response, 
    show_download_button, show_voice_controls, apply_custom_css,
    play_audio_with_feedback, show_voice_status
)
from tools.voice_tool.core import speech_to_text_from_mic_data
from tools.planning_tool.core import execute_create_new_planning_document
from tools.planning_tool.core import execute_collaboration_planning
from tools.planning_tool.core import execute_expand_notion_document
from tools.planning_tool.configs import personas, DOCUMENT_TEMPLATES
from tools.email_tool import get_daily_email_summary, get_email_details
from agents.email_agent import EmailAgent, MailAnalysisAgent
from agents.agent_protocol import AgentMessage, MessageType
from ui_components.prompt_ui import render_prompt_automation_ui, render_prompt_history
# ë°ì´í„° ë¶„ì„ ë„êµ¬ import
try:
    from tools.data_analysis import DataAnalysisTool, ChartGenerator, InsightExtractor
    DATA_ANALYSIS_AVAILABLE = True
except ImportError as e:
    print(f"ë°ì´í„° ë¶„ì„ ë„êµ¬ import ì‹¤íŒ¨: {e}")
    DATA_ANALYSIS_AVAILABLE = False
import uuid
from tools.notion_utils import upload_to_notion
from personas.repository import PersonaRepository

# --- Streamlit í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(
    page_title="AI ê¸°íš ë¹„ì„œ", 
    layout="wide", 
    initial_sidebar_state="expanded",
    menu_items={
        'Get Help': None,
        'Report a bug': None,
        'About': None
    }
)

# CSS ìŠ¤íƒ€ì¼ ì ìš©
apply_custom_css()

def process_user_text_input(text_input: str):
    if not text_input.strip():
        st.warning("ë‚´ìš©ì´ ì—†ëŠ” ë©”ì‹œì§€ëŠ” ì²˜ë¦¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
        
    # ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”
    if "messages" not in st.session_state:
        st.session_state.messages = []
    
    # ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥ (UI í‘œì‹œëŠ” ì±„íŒ… ì»¨í…Œì´ë„ˆì—ì„œ ì²˜ë¦¬)
    st.session_state.messages.append({"role": "user", "content": text_input})
    
    # ìƒíƒœ í‘œì‹œ ì»¨í…Œì´ë„ˆ ìƒì„±
    status_container = st.empty()
    
    # --- ì§„í–‰ìƒí™© ëŒ€ì‹œë³´ë“œ ì—°ë™: LLM ì‘ì—… ì‹œì‘ ---
    st.session_state["current_process"] = {"type": "llm", "desc": "LLM ì…ë ¥ ë¶„ì„ ì¤‘...", "progress": 0.1}
    with show_spinner_ui("ğŸ¤” ìƒê° ì¤‘..."):
        # 1ë‹¨ê³„: ì…ë ¥ ë¶„ì„
        st.session_state["current_process"]["desc"] = "LLM ì…ë ¥ ë¶„ì„ ì¤‘..."
        st.session_state["current_process"]["progress"] = 0.1
        # 2ë‹¨ê³„: ëŒ€í™” ì´ë ¥ ì¤€ë¹„
        st.session_state["current_process"]["desc"] = "ëŒ€í™” ì´ë ¥ ì¤€ë¹„ ì¤‘..."
        st.session_state["current_process"]["progress"] = 0.3
        conversation_history = []
        for msg in st.session_state.messages:
            if msg["role"] in ["user", "assistant"]:
                if "voice_text" in msg and "detailed_text" in msg:
                    conversation_history.append({"role": msg["role"], "content": msg["detailed_text"]})
                elif "content" in msg:
                    conversation_history.append({"role": msg["role"], "content": msg["content"]})
        # --- ì±—ë´‡ íŒŒì¼ ì—…ë¡œë“œ context ì „ë‹¬ ---
        file_context = None
        if "chatbot_uploaded_file" in st.session_state and st.session_state["chatbot_uploaded_file"]:
            file_context = {"uploaded_file": st.session_state["chatbot_uploaded_file"]}
        # 3ë‹¨ê³„: LLM ì‘ë‹µ ëŒ€ê¸° (context ì „ë‹¬)
        st.session_state["current_process"]["desc"] = "LLM ì‘ë‹µ ëŒ€ê¸° ì¤‘..."
        st.session_state["current_process"]["progress"] = 0.5
        # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±: ì—…ë¡œë“œ íŒŒì¼ + ì„ íƒëœ í˜ë¥´ì†Œë‚˜(ìˆì„ ê²½ìš°)
        ctx = {}
        if file_context:
            ctx.update(file_context)
        selected_persona = st.session_state.get("selected_persona")
        if selected_persona:
            ctx["persona"] = selected_persona
        # ì‹¤ì œ í˜¸ì¶œ
        response = assistant_core.process_command_with_llm_and_tools(text_input, conversation_history, context=ctx or None)
        # 4ë‹¨ê³„: LLM ì‘ë‹µ ì²˜ë¦¬
        st.session_state["current_process"]["desc"] = "LLM ì‘ë‹µ ì²˜ë¦¬ ì¤‘..."
        st.session_state["current_process"]["progress"] = 0.8
        
        # ë””ë²„ê¹…ì„ ìœ„í•´ ì‘ë‹µ ë¡œê·¸ ì¶œë ¥
        # ë°”ì´ë„ˆë¦¬ ë°ì´í„° ë¡œê¹… ë°©ì§€ - ì‘ë‹µ ë‚´ìš©ì„ ì•ˆì „í•˜ê²Œ ì¶œë ¥
        safe_response = {}
        for key, value in response.items():
            if key == "audio_content" and isinstance(value, bytes):
                safe_response[key] = f"[Binary audio data of length: {len(value)} bytes]"
            else:
                safe_response[key] = value
        print(f"\n[DEBUG] LLM Response: {safe_response}\n")
        
        if response.get("status") == "success":
            # ì‘ë‹µ íƒ€ì… í™•ì¸
            if response.get("response_type") == "audio_response":
                # ìŒì„± ë° ìƒì„¸ í…ìŠ¤íŠ¸ ì²˜ë¦¬
                voice_text = response.get("voice_text", "")
                detailed_text = response.get("detailed_text", voice_text)
                audio_content = response.get("audio_content", None)
                
                # ë””ë²„ê¹… ì •ë³´ ì¶œë ¥ - ë°”ì´ë„ˆë¦¬ ë°ì´í„° ë¡œê¹… ë°©ì§€ ê°œì„ 
                print(f"\n[DEBUG] Voice Text: {voice_text[:50] if voice_text else 'None'}...\n")
                print(f"\n[DEBUG] Detailed Text: {detailed_text[:50] if detailed_text else 'None'}...\n")
                if isinstance(audio_content, bytes):
                    print(f"\n[DEBUG] Audio Content: Binary data of length {len(audio_content)} bytes\n")
                else:
                    print(f"\n[DEBUG] Audio Content Type: {type(audio_content)}\n")
                
                # ëŒ€í™” ê¸°ë¡ì— ì €ì¥ (UI í‘œì‹œëŠ” ì±„íŒ… ì»¨í…Œì´ë„ˆì—ì„œ ì²˜ë¦¬)
                if voice_text:
                    # ì˜¤ë””ì˜¤ê°€ ìˆëŠ” ê²½ìš° ë¨¼ì € ë©”ì‹œì§€ë¥¼ ì¶”ê°€
                    st.session_state.messages.append({
                        "role": "assistant", 
                        "voice_text": voice_text,
                        "detailed_text": detailed_text
                    })
                    
                    # ì˜¤ë””ì˜¤ ìë™ ì¬ìƒ (UI ì—†ìŒ)
                    if audio_content and isinstance(audio_content, bytes):
                        play_audio_autoplay_hidden(audio_content)
                    else:
                        st.warning("ğŸ’¬ í…ìŠ¤íŠ¸ ì‘ë‹µë§Œ ê°€ëŠ¥í•©ë‹ˆë‹¤. (ì˜¤ë””ì˜¤ ìƒì„± ì‹¤íŒ¨)")
                else:
                    st.error("ì–´ì‹œìŠ¤í„´íŠ¸ ì‘ë‹µ ìƒì„± ì˜¤ë¥˜")
                    print(f"\n[DEBUG] ERROR: Empty voice_text in audio_response\n")
            
            # text_fallback ì‘ë‹µ íƒ€ì… ì²˜ë¦¬
            elif response.get("response_type") == "text_fallback" and response.get("text_content"):
                text_content = response.get("text_content")
                print(f"\n[DEBUG] Text Fallback Content: {text_content[:50]}...\n")
                
                # ëŒ€í™” ê¸°ë¡ì— ì €ì¥ (UI í‘œì‹œëŠ” ì±„íŒ… ì»¨í…Œì´ë„ˆì—ì„œ ì²˜ë¦¬)
                st.session_state.messages.append({
                    "role": "assistant",
                    "voice_text": text_content,
                    "detailed_text": text_content
                })
            
            else:
                # ì¼ë°˜ í…ìŠ¤íŠ¸ ì‘ë‹µ
                message = response.get("message", "") or response.get("response", "") or response.get("text_content", "ì‘ë‹µì´ ì—†ìŠµë‹ˆë‹¤.")
                print(f"\n[DEBUG] Text Response Message: {message}\n")
                
                # ëŒ€í™” ê¸°ë¡ì— ì €ì¥ (UI í‘œì‹œëŠ” ì±„íŒ… ì»¨í…Œì´ë„ˆì—ì„œ ì²˜ë¦¬)
                st.session_state.messages.append({"role": "assistant", "content": message})
        else:
            # ì˜¤ë¥˜ ì‘ë‹µ ì²˜ë¦¬
            error_msg = response.get("message", "") or response.get("response", "ì²˜ë¦¬ ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
            st.error(f"ì˜¤ë¥˜: {error_msg}")
            print(f"\n[DEBUG] ERROR Response: {error_msg}\n")
    # --- ì§„í–‰ìƒí™© ëŒ€ì‹œë³´ë“œ ì—°ë™: LLM ì‘ì—… ì¢…ë£Œ ---
    st.session_state["current_process"] = None

    # í˜ì´ì§€ ë¦¬ë¡œë“œí•˜ì—¬ ìƒˆ ë©”ì‹œì§€ê°€ í‘œì‹œë˜ë„ë¡ í•¨
    # st.rerun() í˜¸ì¶œí•˜ì§€ ì•ŠìŒ

 

# ìŠ¤íƒ€ì¼ì€ ui_components.display_helpers.apply_custom_css()ì—ì„œ ì¤‘ì•™ ê´€ë¦¬ë©ë‹ˆë‹¤.

# --- ì‚¬ì´ë“œë°” UI êµ¬ì„± ---
render_sidebar({})

# --- (ë³´ë¥˜) ì‹ ê·œ ì±—ë´‡ íƒ­ êµ¬í˜„: í˜„ì¬ëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŒ (í–¥í›„ ì‹¤í—˜ìš©ìœ¼ë¡œ 'chatbot_new' í‚¤ ì‚¬ìš©) ---
if st.session_state.get("active_feature") == "chatbot_new":
    st.markdown("#### ğŸ’¬ ì±—ë´‡")
    # ì—…ë¡œë“œ: ì±—ë´‡ ë¬¸ë§¥ íŒŒì¼
    up = st.file_uploader("ì±—ë´‡ì´ ì°¸ê³ í•  íŒŒì¼ ì—…ë¡œë“œ", type=["txt","md","csv","json","xlsx","xls","pdf","docx"], help="í…ìŠ¤íŠ¸/í‘œ ìœ„ì£¼ íŒŒì¼ ê¶Œì¥")
    if up is not None:
        try:
            saved = save_uploaded_file(up)
            st.session_state["chatbot_uploaded_file"] = {"path": saved, "name": up.name, "mime": getattr(up, "type", "")}
            st.success(f"ì—…ë¡œë“œë¨: {saved}")
        except Exception as e:
            st.error(f"íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")
    # ëŒ€í™” í‘œì‹œ
    with st.container():
        for msg in st.session_state.get("messages", []):
            if msg.get("role") == "user" and msg.get("content"):
                st.markdown(f"<div class='user-message'>{msg['content']}</div>", unsafe_allow_html=True)
            elif msg.get("role") == "assistant":
                if "voice_text" in msg or "detailed_text" in msg:
                    txt = msg.get("detailed_text") or msg.get("voice_text")
                    st.markdown(f"<div class='assistant-message'>{txt}</div>", unsafe_allow_html=True)
                elif msg.get("content"):
                    st.markdown(f"<div class='assistant-message'>{msg['content']}</div>", unsafe_allow_html=True)
    # ì…ë ¥ì°½ ë° ì „ì†¡
    user_text = st.text_area("ë©”ì‹œì§€ ì…ë ¥", key="chat_text_input", placeholder="ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”...")
    col_s, col_b = st.columns([4,1])
    with col_b:
        if st.button("ì „ì†¡", type="primary"):
            process_user_text_input(user_text or "")



if st.session_state.get("active_feature") == "document":
    try:
        render_document_ui()
    except Exception as e:
        import traceback
        st.error("ë¬¸ì„œ UI ë Œë”ë§ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
        st.exception(e)
        # ì¶”ê°€ ë””ë²„ê¹… ë¡œê·¸
        try:
            print("[Document UI Error]", e)
            print(traceback.format_exc())
        except Exception:
            pass

 

# --- ë°ì´í„° ë¶„ì„ íƒ­ êµ¬í˜„ (ëª¨ë“ˆí™” UIë§Œ ì‚¬ìš©) ---
if st.session_state.get("active_feature") == "analysis":
    try:
        render_analysis_ui()
    except Exception as e:
        st.error("ë°ì´í„° ë¶„ì„ UI ë Œë”ë§ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
        st.exception(e)

# --- ì´ë©”ì¼ íƒ­ ê°œì„ : ëª¨ë“ˆí™” ë Œë”ëŸ¬ ì‚¬ìš© ---
if st.session_state.get("active_feature") == "email":
    try:
        render_email_ui()
    except Exception as e:
        st.error("ì´ë©”ì¼ UI ë Œë”ë§ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
        st.exception(e)

# --- í”„ë¡¬í”„íŠ¸ ìë™í™” UI ---
if st.session_state.get("active_feature") == "prompt":
    render_prompt_automation_ui()
    render_prompt_history()

# --- ë©”ì¸ UI ë ˆì´ì•„ì›ƒ (í™ˆ/ë””í´íŠ¸: ëª¨ë“ˆí™”ëœ ë ˆê±°ì‹œ ì±—ë´‡ UI) ---
if st.session_state.get("active_feature") in [None, "home"]:
    # ë©”ì¸ ì±— UIë§Œ ë Œë”ë§ (ì‚¬ì´ë“œë°”ëŠ” ìƒë‹¨ì—ì„œ ì´ë¯¸ í•œ ë²ˆ ë Œë”)
    render_chat_ui({})

# --- ì˜¤ë””ì˜¤ ìë™ ì¬ìƒ í•¨ìˆ˜ ---
def play_audio_in_browser(audio_bytes: bytes):
    """
    ì£¼ì–´ì§„ ì˜¤ë””ì˜¤ ë°”ì´íŠ¸ë¥¼ ë¸Œë¼ìš°ì €ì—ì„œ ìë™ ì¬ìƒí•©ë‹ˆë‹¤.
    """
    if not audio_bytes:
        return
    try:
        # (audio_html ë° st.markdown(audio_html, ...) ì½”ë“œ ì™„ì „ ì‚­ì œ)
        pass
    except Exception as e:
        st.error(f"ìŒì„± ì¬ìƒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

# --- ìŒì„± ì¸ì‹ í† ê¸€ ìƒíƒœ í™•ì¸ ë° ì²˜ë¦¬ ---
if st.session_state.voice_recognition_active:
    # í† ê¸€ì´ ì¼œì ¸ ìˆìœ¼ë©´ ìŒì„± ì¸ì‹ ìŠ¤ë ˆë“œ ì‹œì‘
    start_continuous_voice_recognition()
else:
    # í† ê¸€ì´ êº¼ì ¸ ìˆìœ¼ë©´ ìŒì„± ì¸ì‹ ì¤‘ì§€ ì‹œë„
    if "voice_thread" in st.session_state and st.session_state.voice_thread and st.session_state.voice_thread.is_alive():
        stop_continuous_voice_recognition()

def main():
    """
    ì• í”Œë¦¬ì¼€ì´ì…˜ ë©”ì¸ í•¨ìˆ˜
    
    ì´ í•¨ìˆ˜ëŠ” ì•±ì´ ì§ì ‘ ì‹¤í–‰ë  ë•Œ í˜¸ì¶œë©ë‹ˆë‹¤.
    Streamlitì€ ì´ë¯¸ ëª¨ë“  UI ë¡œì§ì„ ì‹¤í–‰í•˜ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” 
    ì¶”ê°€ì ì¸ ì´ˆê¸°í™”ë‚˜ ì„¤ì • ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    """
    logger.info(f"{config.APP_NAME} v{config.APP_VERSION} ì‹œì‘ë¨")
    
    # ìºì‹œ ë¬´íš¨í™”ë¥¼ ìœ„í•œ íƒ€ì„ìŠ¤íƒ¬í”„ ê¸°ë¡
    _cache_invalidation_time = time.time()
    
    # ë¸Œë¼ìš°ì €ì— ì§ì ‘ ìŠ¤í¬ë¦½íŠ¸ ì‚½ì…
    st.markdown("""
    <script>
    // ë¸Œë¼ìš°ì € ìºì‹œ ê°•ì œ ì´ˆê¸°í™”
    if (window.localStorage) {
        // ë§ˆì§€ë§‰ ì´ˆê¸°í™” ì‹œê°„ í™•ì¸
        const lastReset = localStorage.getItem('streamlit_cache_reset');
        const now = Date.now();
        
        // 24ì‹œê°„ë§ˆë‹¤ ìºì‹œ ì´ˆê¸°í™” (86400000 ë°€ë¦¬ì´ˆ)
        if (!lastReset || (now - parseInt(lastReset)) > 3600000) {
            console.log('Forcing cache reset...');
            localStorage.clear();
            sessionStorage.clear();
            localStorage.setItem('streamlit_cache_reset', now.toString());
            // í™”ë©´ ìƒˆë¡œê³ ì¹¨
            setTimeout(() => { location.reload(true); }, 100);
        }
    }
    </script>
    """, unsafe_allow_html=True)
    
    # ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘ ì‹œ ì¶”ê°€ ì„¤ì •ì´ë‚˜ ê²€ì¦ ì‘ì—…ì„ ì—¬ê¸°ì— ì¶”ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
    if config.is_development():
        logger.debug("ê°œë°œ ëª¨ë“œì—ì„œ ì‹¤í–‰ ì¤‘")

if __name__ == "__main__":
    main()